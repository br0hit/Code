{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "### Name:   Bannuru Rohit Kumar Reddy\n",
    "### Roll Number:    21CS30011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries here\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../dataset/cross-validation.csv')\n",
    "print(df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the basic information about the data\n",
    "\n",
    "print(df.head())\n",
    "print(df.dtypes)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Since the number of missing values is not too large, We will drop all the rows which have missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separating the data into the input feautres and the output feature \n",
    "###### Note : We are removing the column 'Loan_ID' from the set of input features as the id will not affect in the prediction of loan status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df.drop(['Loan_Status','Loan_ID'], axis=1)\n",
    "X_df_withloanID = df.drop(['Loan_Status'], axis=1)\n",
    "y_df = df['Loan_Status']\n",
    "\n",
    "print(X_df.shape)\n",
    "print(y_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with categorical data \n",
    "###### We will first have to convert the categorical data into numerical columns before we can train our model, as the model can only take numbers as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the output variable into categories : \n",
    "\n",
    "y_df = y_df.replace('N', 0)  # Replacing N with 0\n",
    "y_df = y_df.replace('Y', 1)  # Replacing Y with 0\n",
    "\n",
    "y_df.head()\n",
    "\n",
    "# Changing the input feature variables into categories : \n",
    "\n",
    "# Columns to be encoded into integers :  Gender, Married, Education, Self_Employed, Property_Area\n",
    "\n",
    "# Changing gender column to 0 and 1 here\n",
    "X_df['Gender'] = X_df['Gender'].apply(lambda x: 0 if x == 'Male' else 1)\n",
    "\n",
    "# Changing married column to 0 and 1 here\n",
    "X_df['Married'] = X_df['Married'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# Changing education column to 0 and 1 here\n",
    "X_df['Education'] = X_df['Education'].apply(lambda x: 0 if x == 'Graduate' else 1)\n",
    "\n",
    "# Changing self employed column to 0 and 1 here\n",
    "X_df['Self_Employed'] = X_df['Self_Employed'].apply(lambda x: 0 if x == 'Yes' else 1)\n",
    "\n",
    "# encoding the property area column here\n",
    "X_final = pd.get_dummies(X_df, columns=['Property_Area'])\n",
    "\n",
    "# Preprocess the 'Dependents' column to convert '3+' to a numeric value\n",
    "X_final['Dependents'] = X_final['Dependents'].replace('3+', 3).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the Standard Scalar on the numerical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_final[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Dependents']] = scaler.fit_transform(X_final[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Dependents']])\n",
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create an array of shuffled indexes\n",
    "data_indexes = np.arange(len(X_final))\n",
    "np.random.shuffle(data_indexes)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Calculate the size of each fold\n",
    "fold_size = len(data_indexes) // num_folds\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold_num in range(num_folds):\n",
    "    # Determine the current fold's start and end indexes\n",
    "    start_idx = fold_num * fold_size\n",
    "    end_idx = (fold_num + 1) * fold_size if fold_num < (num_folds - 1) else len(data_indexes)\n",
    "    \n",
    "    # Extract the current fold's indexes\n",
    "    current_fold_indexes = data_indexes[start_idx:end_idx]\n",
    "    \n",
    "    # Create training and testing sets based on the fold indexes\n",
    "    training_indexes = [idx for idx in data_indexes if idx not in current_fold_indexes]\n",
    "    X_train, y_train = X_final.iloc[training_indexes], y_df.iloc[training_indexes]\n",
    "    X_test, y_test = X_final.iloc[current_fold_indexes], y_df.iloc[current_fold_indexes]\n",
    "    \n",
    "    # Train your model (replace this with your model training code)\n",
    "    # For example, you can use a Logistic Regression model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics (replace this with your evaluation code)\n",
    "    # For example, you can calculate accuracy, precision, and recall\n",
    "    fold_accuracy = np.mean(y_pred == y_test)\n",
    "    fold_precision = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_pred == 1)\n",
    "    fold_recall = np.sum((y_pred == 1) & (y_test == 1)) / np.sum(y_test == 1)\n",
    "    \n",
    "    # Append evaluation metrics to the respective lists\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    fold_precisions.append(fold_precision)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "# Calculate and print the mean evaluation metrics across all folds\n",
    "mean_fold_accuracy = np.mean(fold_accuracies)\n",
    "mean_fold_precision = np.mean(fold_precisions)\n",
    "mean_fold_recall = np.mean(fold_recalls)\n",
    "\n",
    "# Print the mean evaluation metrics\n",
    "print(f\"Mean Accuracy: {mean_fold_accuracy:.4f}\")\n",
    "print(f\"Mean Precision: {mean_fold_precision:.4f}\")\n",
    "print(f\"Mean Recall: {mean_fold_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
